{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict HFpEF two-year re-admission\n",
    "\n",
    "use trained model to predict the re-admission.\n",
    "\n",
    "Make sure you have run/read step1 code.\n",
    "\n",
    "---\n",
    "\n",
    "### Docker environment\n",
    "Please use `docker/docker_torch`, make sure you install ```torch_geometric``` package\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/workspace/Documents\") \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "from itertools import combinations\n",
    "from itertools import chain\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nb\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline\n",
    "import HFpEF_CMR_GraphStrain.functions_collection as ff\n",
    "import HFpEF_CMR_GraphStrain.Data_processing as dp\n",
    "import HFpEF_CMR_GraphStrain.helpers.load_data as load_data\n",
    "import HFpEF_CMR_GraphStrain.helpers.generator as generator\n",
    "import HFpEF_CMR_GraphStrain.helpers.train_func as train_func\n",
    "import HFpEF_CMR_GraphStrain.helpers.STGCN as STGCN\n",
    "import HFpEF_CMR_GraphStrain.helpers.best_epoch as best_epoch\n",
    "\n",
    "\n",
    "main_path = '/mnt/camca_NAS/Deepstrain/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1: process the regional LV strain\n",
    "\n",
    "1. our default time frame number = 25. Running this code will interpolate time frames if original one is not 25\n",
    "\n",
    "2. our strains were saved for each time frame. running this code will process them in a big matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5)\n",
      "original shape: (16, 15) (16, 15)\n"
     ]
    }
   ],
   "source": [
    "# define the patient list \n",
    "patient_list = pd.read_excel(os.path.join(main_path, 'example_data/Patient_list/patient_list.xlsx'))\n",
    "patient_list = patient_list[patient_list['include?'] == 'yes']\n",
    "print(patient_list.shape)\n",
    "\n",
    "for i in range(0, patient_list.shape[0]):\n",
    "    patient_id = ff.XX_to_ID_00XX(patient_list.iloc[i, 0])\n",
    "\n",
    "    # put into a big matrix\n",
    "    folders = ff.sort_timeframe(ff.find_all_target_files(['tf_*'],os.path.join(main_path,'example_data/results/strain',patient_id)), 0,'_','')\n",
    "    Ecc_aha_ori = np.zeros((len(folders),16))\n",
    "    Err_aha_ori = np.zeros((len(folders),16))\n",
    "\n",
    "    for i in range(len(folders)):\n",
    "        strain_file = np.load(os.path.join(folders[i],'strain_info.npy'),allow_pickle=True)\n",
    "        ecc_aha = np.asarray(strain_file[-2][:-1] )\n",
    "        err_aha = np.asarray(strain_file[-1][:-1] )\n",
    "        Ecc_aha_ori[i] = ecc_aha\n",
    "        Err_aha_ori[i] = err_aha\n",
    "\n",
    "    Ecc_aha = np.zeros((16, len(folders))); Err_aha = np.zeros((16, len(folders)))\n",
    "    for i in range(0,16):\n",
    "        for j in range(len(folders)):\n",
    "            Ecc_aha[i,j] = Ecc_aha_ori[j,i]\n",
    "            Err_aha[i,j] = Err_aha_ori[j,i]\n",
    "\n",
    "    print('original shape:', Ecc_aha.shape, Err_aha.shape)\n",
    "\n",
    "    # sample 25 time frames\n",
    "    x_original = np.arange(0,Ecc_aha.shape[1])\n",
    "    x_new = np.linspace(0, Ecc_aha.shape[1]-1, 25)  # 25 time frames\n",
    "\n",
    "    Ecc_aha_sample = np.zeros((16,25))\n",
    "    Err_aha_sample = np.zeros((16,25))\n",
    "\n",
    "    for i in range(16):\n",
    "        spl_ecc = make_interp_spline(x_original, Ecc_aha[i,:], k=2)  # k=3表示三次样条\n",
    "        ecc_new = spl_ecc(x_new)\n",
    "\n",
    "        spl_err = make_interp_spline(x_original, Err_aha[i,:], k=2)  # k=3表示三次样条\n",
    "        err_new = spl_err(x_new)\n",
    "\n",
    "        Ecc_aha_sample[i] = ecc_new\n",
    "        Err_aha_sample[i] = err_new\n",
    "\n",
    "    np.save(os.path.join(main_path, 'example_data/results/strain', patient_id, 'Ecc_aha_sample.npy'), Ecc_aha_sample)\n",
    "    np.save(os.path.join(main_path, 'example_data/results/strain', patient_id, 'Err_aha_sample.npy'), Err_aha_sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2: Train Graph Convolutional Network\n",
    "we can also add EHR data if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of Ecc, Err: (16, 25) (12, 25)\n",
      "X_Ecc.shape: (1, 16, 25)  X_Err.shape: (1, 12, 25)  Y.shape: (1,)\n",
      "ehr_array.shape: (1, 27)\n",
      "ehr_array.shape: (1, 27)  features: ['Age', 'Sex', 'BloodPressureSystolic', 'BloodPressureDiastolic', 'HeartRate', 'Weight', 'BMI', 'HGB', 'Glucose', 'Sodium', 'BUN', 'AtrialFibrillation', 'CoronaryVascularDisease', 'MyocardialInfarction', 'Diabetes', 'Hypertension', 'ChronicKidneyDisease', 'Obesity', 'Anemia', 'Cardiomyopathy', 'MetabolicSyndrome', 'Neoplasm', 'Diuretics', 'BetaBlockers', 'ACEI', 'CCB', 'Statin']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "label_sheet = pd.read_excel(os.path.join(main_path, 'example_data/Patient_list/patient_list.xlsx'))\n",
    "\n",
    "strain_loader = load_data.Load(os.path.join(main_path, 'example_data/results/'))\n",
    "X_Ecc, X_Err, Y = strain_loader.load_strain(label_sheet)\n",
    "print('X_Ecc.shape:', X_Ecc.shape, ' X_Err.shape:', X_Err.shape, ' Y.shape:', Y.shape)\n",
    "\n",
    "# load EHR if needed\n",
    "ehr_sheet = pd.read_excel(os.path.join(main_path, 'example_data/Patient_list/patient_clinical_data.xlsx'))\n",
    "\n",
    "ehr_loader = load_data.Load(main_path)\n",
    "ehr_array, features = ehr_loader.load_ehr(ehr_sheet)\n",
    "print('ehr_array.shape:', ehr_array.shape, ' features:', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 64])\n",
      "torch.Size([2, 36])\n"
     ]
    }
   ],
   "source": [
    "# define GCN\n",
    "# define the edge matrix\n",
    "edge_index_ecc, edge_index_err = STGCN.edge_index_cal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "# as example code, we train and validate model on the same one case. \n",
    "# please use your own data to train and validate the model.\n",
    "\n",
    "model_name = 'GCN_Ecc_Err' # GCN_Ecc_Err_EHR if you want to add clinical data as input\n",
    "strain = 'both' # define whether to use Ecc, Err, or both\n",
    "save_folder = os.path.join(main_path, 'example_data/models/', model_name, 'models')\n",
    "ff.make_folder([os.path.join(main_path,'example_data/models'), os.path.join(main_path,'example_data/models', model_name), save_folder, os.path.join(main_path,'example_data/models', model_name, 'log')])\n",
    "\n",
    "train,val = [0], [0]\n",
    "# define Y_train\n",
    "Y_train = Y[train]\n",
    "# count positive and negative samples\n",
    "num_neg,num_pos= (Y_train == 0).sum().item(),(Y_train == 1).sum().item()\n",
    "pos_weight_value =  torch.tensor([1.], dtype=torch.float32) #torch.tensor([num_neg / num_pos], dtype=torch.float32)\n",
    "  \n",
    "# weight loss\n",
    "weighted_bce_loss = train_func.WeightedBCELoss(pos_weight_value)\n",
    "\n",
    "# define data generator\n",
    "generator_train = generator.Data_generator(X_Ecc, X_Err, Y, train, shuffle = True) if 'EHR' not in model_name else generator.Data_generator(X_Ecc, X_Err, Y, train, shuffle = True, EHR = ehr_array)\n",
    "generator_val = generator.Data_generator(X_Ecc, X_Err, Y, val, shuffle = False) if 'EHR' not in model_name else generator.Data_generator(X_Ecc, X_Err, Y, val, shuffle = False, EHR = ehr_array)\n",
    "\n",
    "if 'EHR' not in model_name:\n",
    "  # define model, parameters are default (no need to change)\n",
    "  if strain == 'Ecc' or strain == 'Err' :\n",
    "    model = STGCN.STGCN(strain = strain,GCN_type ='ChebConv', Cheb_K = 2, aha_num = 16, tf_num = 25, temporal_out = 0, hidden_size=128, dropout_rate=0.3, edge_index_ecc= edge_index_ecc , edge_index_err = edge_index_err, get_latent_layer = False)\n",
    "  elif strain == 'both':\n",
    "    model = STGCN.DualSTGCN(fusion_method= 'gated', GCN_type = 'ChebConv', Cheb_K = 2, aha_num = 16, tf_num = 25, temporal_out= 0,  hidden_size=128, dropout_rate=0.3, edge_index_ecc = edge_index_ecc, edge_index_err = edge_index_err)\n",
    "  \n",
    "if 'EHR' in model_name: # use Ecc, Err and EHR\n",
    "    model = STGCN.DualSTGCN_w_EHR(fusion_method= 'gated', ehr_dim = ehr_array.shape[-1], ehr_out = 128, GCN_type = 'ChebConv', Cheb_K = 2, aha_num = 16, tf_num = 25, temporal_out= 0,  hidden_size=128, dropout_rate=0.3, edge_index_ecc = edge_index_ecc, edge_index_err = edge_index_err)\n",
    "      \n",
    "# train\n",
    "trainer = train_func.Trainer(model, \n",
    "                            weighted_bce_loss, \n",
    "                            generator_train, \n",
    "                            generator_val, \n",
    "                            train_batch_size = 1, \n",
    "                            train_num_steps = 2000, \n",
    "                            train_lr_decay_every = 1000,\n",
    "                            save_folder = save_folder, \n",
    "                            save_models_every = 10,\n",
    "                            lr = 0.0001)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3: Predict using trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of Ecc, Err: (16, 25) (12, 25)\n",
      "X_Ecc.shape: (1, 16, 25)  X_Err.shape: (1, 12, 25)  Y.shape: (1,)\n",
      "ehr_array.shape: (1, 27)\n",
      "ehr_array.shape: (1, 27)  features: ['Age', 'Sex', 'BloodPressureSystolic', 'BloodPressureDiastolic', 'HeartRate', 'Weight', 'BMI', 'HGB', 'Glucose', 'Sodium', 'BUN', 'AtrialFibrillation', 'CoronaryVascularDisease', 'MyocardialInfarction', 'Diabetes', 'Hypertension', 'ChronicKidneyDisease', 'Obesity', 'Anemia', 'Cardiomyopathy', 'MetabolicSyndrome', 'Neoplasm', 'Diuretics', 'BetaBlockers', 'ACEI', 'CCB', 'Statin']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "label_sheet = pd.read_excel(os.path.join(main_path, 'example_data/Patient_list/patient_list.xlsx'))\n",
    "\n",
    "strain_loader = load_data.Load(os.path.join(main_path, 'example_data/results/'))\n",
    "X_Ecc, X_Err, Y = strain_loader.load_strain(label_sheet)\n",
    "print('X_Ecc.shape:', X_Ecc.shape, ' X_Err.shape:', X_Err.shape, ' Y.shape:', Y.shape)\n",
    "\n",
    "# load EHR if needed\n",
    "ehr_sheet = pd.read_excel(os.path.join(main_path, 'example_data/Patient_list/patient_clinical_data.xlsx'))\n",
    "\n",
    "ehr_loader = load_data.Load(main_path)\n",
    "ehr_array, features = ehr_loader.load_ehr(ehr_sheet)\n",
    "print('ehr_array.shape:', ehr_array.shape, ' features:', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 64])\n",
      "torch.Size([2, 36])\n"
     ]
    }
   ],
   "source": [
    "# define GCN\n",
    "# define the edge matrix\n",
    "edge_index_ecc, edge_index_err = STGCN.edge_index_cal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_prob: 0.929652750492096\n",
      "y true: 1.0\n"
     ]
    }
   ],
   "source": [
    "# predict \n",
    "model_name = 'GCN_Ecc_Err'\n",
    "strain = 'both'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define file\n",
    "trained_model_filename = os.path.join(main_path, 'example_data/models', model_name, 'models', 'model-final.pt')\n",
    "\n",
    "val = [0]\n",
    "# define generator\n",
    "generator_val = generator.Data_generator(X_Ecc, X_Err, Y, val, shuffle = False) if 'EHR' not in model_name else generator.Data_generator(X_Ecc, X_Err, Y, val, shuffle = False, EHR = ehr_array)\n",
    "dl_val= generator.DataLoader(generator_val, batch_size = 1, shuffle = False, pin_memory = True, num_workers = 0)\n",
    "\n",
    "# define model\n",
    "if 'EHR' not in model_name:\n",
    "  # define model, parameters are default (no need to change)\n",
    "  if strain == 'Ecc' or strain == 'Err' :\n",
    "    model = STGCN.STGCN(strain = strain,GCN_type ='ChebConv', Cheb_K = 2, aha_num = 16, tf_num = 25, temporal_out = 0, hidden_size=128, dropout_rate=0.3, edge_index_ecc= edge_index_ecc , edge_index_err = edge_index_err, get_latent_layer = False)\n",
    "  elif strain == 'both':\n",
    "    model = STGCN.DualSTGCN(fusion_method= 'gated', GCN_type = 'ChebConv', Cheb_K = 2, aha_num = 16, tf_num = 25, temporal_out= 0,  hidden_size=128, dropout_rate=0.3, edge_index_ecc = edge_index_ecc, edge_index_err = edge_index_err)\n",
    "  \n",
    "if 'EHR' in model_name: # use Ecc, Err and EHR\n",
    "    model = STGCN.DualSTGCN_w_EHR(fusion_method= 'gated', ehr_dim = ehr_array.shape[-1], ehr_out = 128, GCN_type = 'ChebConv', Cheb_K = 2, aha_num = 16, tf_num = 25, temporal_out= 0,  hidden_size=128, dropout_rate=0.3, edge_index_ecc = edge_index_ecc, edge_index_err = edge_index_err)\n",
    "      \n",
    "\n",
    "trainer = train_func.Trainer(model, None, generator_val, generator_val, train_batch_size = 1, train_num_steps = 1, save_folder = os.path.join(main_path, 'example_data/models'), train_lr_decay_every = 1, save_models_every = 1)\n",
    "trainer.load_model(trained_model_filename)\n",
    "model.eval()\n",
    "\n",
    "for batch in dl_val:\n",
    "    batch_Ecc, batch_Err, batch_Err_padded, batch_y , batch_ehr = batch\n",
    "    data_Ecc, data_Err, data_Err_padded, data_y, data_ehr = batch_Ecc.to(device), batch_Err.to(device), batch_Err_padded.to(device), batch_y.to(device), batch_ehr.to(device)\n",
    "    # predict\n",
    "    with torch.no_grad():\n",
    "        if strain == 'Err':\n",
    "            y_pred_prob = model(data_Err)\n",
    "        elif strain == 'Ecc':\n",
    "            y_pred_prob = model(data_Ecc)\n",
    "        else:\n",
    "            if 'EHR' not in model_name:\n",
    "                y_pred_prob  = model(data_Ecc, data_Err)\n",
    "            else:\n",
    "                y_pred_prob = model(data_Ecc, data_Err, data_ehr)\n",
    "\n",
    "        print('y_pred_prob:', y_pred_prob.item())\n",
    "        print('y true:', data_y.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
